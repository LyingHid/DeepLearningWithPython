{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e86d4d-731b-4888-bfbd-6127c606a0a1",
   "metadata": {},
   "source": [
    "# Advanced architecture patterns\n",
    "\n",
    "We covered one important design pattern in detail in the previous section: residual\n",
    "connections. There are two more design patterns you should know about: normaliza-\n",
    "tion and depthwise separable convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2052b-a910-4795-a6af-035ffdc50112",
   "metadata": {},
   "source": [
    "## BATCH NORMALIZATION\n",
    "\n",
    "Batch normalization is a type of layer (BatchNormalization in Keras) introduced\n",
    "in 2015 by Ioffe and Szegedy; it can adaptively normalize data even as the mean and\n",
    "variance change over time during training. It works by internally maintaining an expo-\n",
    "nential moving average of the batch-wise mean and variance of the data seen during\n",
    "training. The main effect of batch normalization is that it helps with gradient propa-\n",
    "gation—much like residual connections—and thus allows for deeper networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a3c34-e344-4036-b4a4-4db7349a72a1",
   "metadata": {},
   "source": [
    "## DEPTHWISE SEPARABLE CONVOLUTION\n",
    "\n",
    "What if I told you that there’s a layer you can use as a drop-in replacement for Conv2D\n",
    "that will make your model lighter (fewer trainable weight parameters) and faster\n",
    "(fewer floating-point operations) and cause it to perform a few percentage points bet-\n",
    "ter on its task? That is precisely what the depthwise separable convolution layer does\n",
    "(SeparableConv2D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78270858-bb46-4d53-a6d6-5ed3adb41167",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "Often, it turns out that random\n",
    "search (choosing hyperparameters to evaluate at random, repeatedly) is the best solu-\n",
    "tion, despite being the most naive one. But one tool I have found reliably better than\n",
    "random search is Hyperopt (https://github.com/hyperopt/hyperopt), a Python\n",
    "library for hyperparameter optimization that internally uses trees of Parzen estimators\n",
    "to predict sets of hyperparameters that are likely to work well. Another library called\n",
    "Hyperas (https://github.com/maxpumperla/hyperas) integrates Hyperopt for use\n",
    "with Keras models. Do check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ba9c1-8243-4cc9-ac72-df0bd8705020",
   "metadata": {},
   "source": [
    "## Model ensembling\n",
    "\n",
    "Ensembling consists of pooling together the predictions of a set of differ-\n",
    "ent models, to produce better predictions. If you look at machine-learning competi-\n",
    "tions, in particular on Kaggle, you’ll see that the winners use very large ensembles of\n",
    "models that inevitably beat any single model, no matter how good.\n",
    "\n",
    "\n",
    "The easiest way to pool the predictions of a set\n",
    "of classifiers (to ensemble the classifiers) is to average their predictions at inference time.\n",
    "\n",
    "\n",
    "A smarter way to ensemble classifiers is to do a weighted average, where the\n",
    "weights are learned on the validation data—typically, the better classifiers are given a\n",
    "higher weight, and the worse classifiers are given a lower weight.\n",
    "\n",
    "\n",
    "Diversity is what makes ensembling work\n",
    "\n",
    "\n",
    "you should ensemble models that are as good as possible while being\n",
    "as different as possible.\n",
    "\n",
    "\n",
    "In recent times, one style of basic ensemble that has been very successful in prac-\n",
    "tice is the wide and deep category of models, blending deep learning with shallow learn-\n",
    "ing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
